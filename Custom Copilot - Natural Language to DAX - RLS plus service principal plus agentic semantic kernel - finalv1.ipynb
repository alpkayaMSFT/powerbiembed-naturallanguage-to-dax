{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Notebook header / notes. Not required for execution ‚Äî informational only.\n",
    "# User asks a question\n",
    "# agents accepts the question / agent does a lookup on the user / regular user or rls user\n",
    "# if regular user then no RLS applied otherwise if rls user then Country='Canada' applied\n",
    "# generates a DAX statement with rls or with regular\n",
    "# DAX statement is issued to PBI Semantic Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./3 Steps - Enhance Your Power BI Embed Solution - Custom Copilot Architecture.png\" alt=\"Description\" style=\"max-width:100%; height:auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ Semantic Kernel Agentic DAX Copilot\n",
    "\n",
    "This notebook demonstrates an **agentic approach** to natural language ‚Üí DAX query generation using:\n",
    "- **Semantic Kernel** for agent orchestration\n",
    "- **Plugin-based architecture** for modularity  \n",
    "- **Service principal authentication** for Power BI access\n",
    "- **Row-level security (RLS)** support\n",
    "\n",
    "## Architecture Overview:\n",
    "```\n",
    "ü§ñ DAX Copilot Agent\n",
    "‚îú‚îÄ‚îÄ üë§ UserContextPlugin ‚Üí Determines RLS context\n",
    "‚îú‚îÄ‚îÄ üß† DAXGenerationPlugin ‚Üí Natural language ‚Üí DAX\n",
    "‚îú‚îÄ‚îÄ üîê AuthenticationPlugin ‚Üí Service principal tokens  \n",
    "‚îî‚îÄ‚îÄ üìä QueryExecutionPlugin ‚Üí Execute DAX ‚Üí DataFrame\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Install Semantic Kernel and Dependencies\n",
    "%pip install semantic-kernel --quiet\n",
    "%pip install msal --quiet  \n",
    "%pip install pandas --quiet\n",
    "%pip install pythonnet --quiet\n",
    "\n",
    "print(\"‚úÖ Semantic Kernel and dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Configuration and Core Imports\n",
    "import asyncio\n",
    "import os\n",
    "from typing import Annotated\n",
    "\n",
    "# Semantic Kernel imports\n",
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.functions import kernel_function\n",
    "from semantic_kernel.kernel import Kernel\n",
    "\n",
    "# Data and auth imports\n",
    "import pandas as pd\n",
    "import msal\n",
    "import base64\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"‚úÖ Core imports loaded!\")\n",
    "\n",
    "# Configuration\n",
    "AZURE_OPENAI_API_KEY = \"youraoaikey\"\n",
    "AZURE_OPENAI_ENDPOINT = \"youraoaiendpoint\"\n",
    "AZURE_OPENAI_DEPLOYMENT = \"youraoaideployment\"\n",
    "API_VERSION = \"youraoaiapiversion\"\n",
    "\n",
    "# Service Principal Configuration\n",
    "CLIENT_ID = \"yourserviceprincipalclientid\"\n",
    "CLIENT_SECRET = \"yourserviceprincipalclientsecret\"\n",
    "TENANT_ID = \"yourserviceprincipaltenantid\"\n",
    "\n",
    "# Power BI Configuration\n",
    "POWERBI_WORKSPACE = \"yourpowerbiworkspacename\"\n",
    "SEMANTIC_MODEL = \"yoursemanticmodelname\"\n",
    "\n",
    "print(\"‚úÖ Configuration loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing UserContext Plugin:\n",
      "Regular user: {\n",
      "  \"user\": \"regular_user@customer.com\",\n",
      "  \"user_type\": \"regular\",\n",
      "  \"rls_filter\": null,\n",
      "  \"rls_instruction\": \"\"\n",
      "}\n",
      "\n",
      "RLS user: {\n",
      "  \"user\": \"user1@customer.com\",\n",
      "  \"user_type\": \"rls\",\n",
      "  \"rls_filter\": \"DimSalesTerritory[Sales Territory Country] = \\\"Canada\\\"\",\n",
      "  \"rls_instruction\": \"Row-level security: Always apply the following DAX filter in your query: FILTER(DimSalesTerritory, DimSalesTerritory[Sales Territory Country] = \\\"Canada\\\")\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# üë§ UserContext Plugin - Determines RLS Context\n",
    "class UserContextPlugin:\n",
    "    \"\"\"Plugin to determine user context and RLS requirements\"\"\"\n",
    "    \n",
    "    @kernel_function(\n",
    "        description=\"Determines if a user requires row-level security filtering\",\n",
    "        name=\"get_user_rls_context\",\n",
    "    )\n",
    "    def get_user_rls_context(\n",
    "        self, \n",
    "        user_type: Annotated[str, \"Type of user: 'rls' for restricted, 'regular' for unrestricted\"] = \"regular\"\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Determines the RLS context for a user.\n",
    "        Returns JSON string with user context information.\n",
    "        \"\"\"\n",
    "        if user_type.lower() == 'rls':\n",
    "            context = {\n",
    "                'user': 'user1@customer.com',\n",
    "                'user_type': 'rls',\n",
    "                'rls_filter': 'DimSalesTerritory[Sales Territory Country] = \"Canada\"',\n",
    "                'rls_instruction': 'Row-level security: Always apply the following DAX filter in your query: FILTER(DimSalesTerritory, DimSalesTerritory[Sales Territory Country] = \"Canada\")'\n",
    "            }\n",
    "        else:\n",
    "            context = {\n",
    "                'user': 'regular_user@customer.com', \n",
    "                'user_type': 'regular',\n",
    "                'rls_filter': None,\n",
    "                'rls_instruction': ''\n",
    "            }\n",
    "        \n",
    "        return json.dumps(context, indent=2)\n",
    "\n",
    "# Test the plugin\n",
    "user_plugin = UserContextPlugin()\n",
    "print(\"üß™ Testing UserContext Plugin:\")\n",
    "print(\"Regular user:\", user_plugin.get_user_rls_context(\"regular\"))\n",
    "print(\"\\nRLS user:\", user_plugin.get_user_rls_context(\"rls\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîê AuthenticationPlugin - Service Principal Token Management\n",
    "class AuthenticationPlugin:\n",
    "    \"\"\"Plugin to handle service principal authentication for Power BI\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.client_id = CLIENT_ID\n",
    "        self.client_secret = CLIENT_SECRET\n",
    "        self.tenant_id = TENANT_ID\n",
    "        self.authority = f\"https://login.microsoftonline.com/{self.tenant_id}\"\n",
    "        \n",
    "    @kernel_function(\n",
    "        description=\"Acquires Azure AD access token for Power BI using service principal\",\n",
    "        name=\"get_powerbi_token\",\n",
    "    )\n",
    "    def get_powerbi_token(self) -> str:\n",
    "        \"\"\"\n",
    "        Acquires access token for Power BI API using service principal credentials\n",
    "        Returns: JSON string with token information\n",
    "        \"\"\"\n",
    "        try:\n",
    "            app = msal.ConfidentialClientApplication(\n",
    "                self.client_id,\n",
    "                client_credential=self.client_secret,\n",
    "                authority=self.authority\n",
    "            )\n",
    "            \n",
    "            token_result = app.acquire_token_for_client(\n",
    "                scopes=[\"https://analysis.windows.net/powerbi/api/.default\"]\n",
    "            )\n",
    "            \n",
    "            if 'access_token' not in token_result:\n",
    "                raise RuntimeError(f\"Failed to acquire token: {token_result}\")\n",
    "            \n",
    "            # Parse token expiry\n",
    "            access_token = token_result['access_token']\n",
    "            try:\n",
    "                payload_b64 = access_token.split('.')[1]\n",
    "                payload_b64 += '=' * (-len(payload_b64) % 4)\n",
    "                payload = json.loads(base64.urlsafe_b64decode(payload_b64).decode('utf8'))\n",
    "                exp = int(payload.get('exp'))\n",
    "            except Exception:\n",
    "                exp = int(time.time()) + int(token_result.get('expires_in', 3600))\n",
    "            \n",
    "            result = {\n",
    "                'access_token': access_token,\n",
    "                'expires_at': exp,\n",
    "                'token_type': token_result.get('token_type', 'Bearer'),\n",
    "                'status': 'success'\n",
    "            }\n",
    "            \n",
    "            return json.dumps(result, indent=2)\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_result = {\n",
    "                'status': 'error',\n",
    "                'error_message': str(e),\n",
    "                'access_token': None\n",
    "            }\n",
    "            return json.dumps(error_result, indent=2)\n",
    "\n",
    "# Test the AuthenticationPlugin\n",
    "auth_plugin = AuthenticationPlugin()\n",
    "print(\"üß™ Testing AuthenticationPlugin:\")\n",
    "token_result = auth_plugin.get_powerbi_token()\n",
    "print(\"Token acquired:\", \"‚úÖ\" if \"success\" in token_result else \"‚ùå\")\n",
    "if \"success\" in token_result:\n",
    "    print(\"Token preview (first 50 chars):\", json.loads(token_result)['access_token'][:50] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ Enhanced DAX Generation Plugin - Production Ready with Real LLM\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "class EnhancedDAXGenerationPlugin:\n",
    "    \"\"\"Production-ready DAX Generation Plugin with real Azure OpenAI integration\"\"\"\n",
    "    \n",
    "    def __init__(self, azure_openai_client):\n",
    "        self.client = azure_openai_client\n",
    "        self.semantic_model_metadata = \"\"\"\n",
    "Semantic model metadata:\n",
    "- Table: FactInternetSales\n",
    "    ‚Ä¢ FactInternetSales[SalesAmount] (decimal)\n",
    "    ‚Ä¢ FactInternetSales[Transaction Count] (decimal) \n",
    "    ‚Ä¢ FactInternetSales[OrderDate] (date)\n",
    "    ‚Ä¢ FactInternetSales table contains a measure 'Revenue'=Sum(FactInternetSales[SalesAmount]) and another measure called 'Sales'='Revenue'=Sum(FactInternetSales[SalesAmount])\n",
    "- Table: DimSalesTerritory\n",
    "    ‚Ä¢ DimSalesTerritory[SalesTerritoryKey] (int)\n",
    "    ‚Ä¢ DimSalesTerritory[Sales Territory Region] (string) \n",
    "    ‚Ä¢ DimSalesTerritory[Sales Territory Country] (string)\n",
    "- Table: DimDate\n",
    "    ‚Ä¢ DimDate[DateKey] (int)\n",
    "    ‚Ä¢ DimDate[CalendarYear] (int)\n",
    "\n",
    "Relationships:\n",
    "- FactInternetSales[SalesTerritoryKey] ‚Üí DimSalesTerritory[SalesTerritoryKey]\n",
    "- FactInternetSales[DateKey] ‚Üí DimDate[DateKey]\n",
    "\"\"\"\n",
    "    \n",
    "    @kernel_function(\n",
    "        description=\"Generates DAX query from natural language using Azure OpenAI with RLS support\",\n",
    "        name=\"generate_dax_query_llm\",\n",
    "    )\n",
    "    def generate_dax_query_llm(\n",
    "        self,\n",
    "        question: Annotated[str, \"Natural language question about data\"],\n",
    "        user_context: Annotated[str, \"JSON string with user context including RLS requirements\"] = \"{}\"\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Generates a DAX query from natural language using Azure OpenAI LLM\n",
    "        Handles RLS filtering automatically based on user context\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Parse user context\n",
    "            context = json.loads(user_context)\n",
    "            rls_instruction = context.get('rls_instruction', '')\n",
    "            \n",
    "            # Build system message with RLS context\n",
    "            system_message = f'''You are a Power BI DAX expert. Generate only the DAX query.\n",
    "Do not include explanations, markdown, triple backticks, or language tags.\n",
    "\n",
    "{self.semantic_model_metadata.strip()}\n",
    "{rls_instruction}'''\n",
    "\n",
    "            # Call Azure OpenAI with structured prompt\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=AZURE_OPENAI_DEPLOYMENT,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_message.strip()},\n",
    "                    {\"role\": \"user\", \"content\": question}\n",
    "                ],\n",
    "                temperature=0\n",
    "            )\n",
    "            \n",
    "            # Clean and return the DAX query\n",
    "            import re\n",
    "            dax_query = re.sub(\n",
    "                r\"^```[^\\n]*\\n|\\n```$\", \n",
    "                \"\", \n",
    "                response.choices[0].message.content, \n",
    "                flags=re.MULTILINE\n",
    "            ).strip()\n",
    "            \n",
    "            return dax_query\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error generating DAX query: {str(e)}\"\n",
    "\n",
    "# Initialize Azure OpenAI client for production plugin\n",
    "enhanced_openai_client = AzureOpenAI(\n",
    "    api_version=API_VERSION,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT\n",
    ")\n",
    "\n",
    "# Create the production-ready enhanced plugin\n",
    "enhanced_dax_plugin = EnhancedDAXGenerationPlugin(enhanced_openai_client)\n",
    "print(\"‚úÖ Enhanced DAX Generation Plugin created with real Azure OpenAI integration!\")\n",
    "print(\"üß† This plugin encapsulates LLM calls within the agentic architecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üè≠ Production Kernel & Agent - Complete 4-Plugin Architecture\n",
    "\n",
    "async def initialize_production_kernel():\n",
    "    \"\"\"Initialize Production Kernel with all 4 plugins for complete workflow\"\"\"\n",
    "    kernel = Kernel()\n",
    "    \n",
    "    # Add Azure OpenAI service\n",
    "    kernel.add_service(\n",
    "        AzureChatCompletion(\n",
    "            deployment_name=AZURE_OPENAI_DEPLOYMENT,\n",
    "            endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "            api_key=AZURE_OPENAI_API_KEY,\n",
    "            api_version=API_VERSION,\n",
    "            service_id=\"aoai\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Add all production plugins\n",
    "    kernel.add_plugin(UserContextPlugin(), plugin_name=\"UserContext\")\n",
    "    kernel.add_plugin(enhanced_dax_plugin, plugin_name=\"DAXGeneration\") \n",
    "    kernel.add_plugin(AuthenticationPlugin(), plugin_name=\"Authentication\")\n",
    "    kernel.add_plugin(QueryExecutionPlugin(), plugin_name=\"QueryExecution\")\n",
    "    \n",
    "    print(\"üè≠ Production Kernel initialized with:\")\n",
    "    print(\"  üåê Azure OpenAI service\")\n",
    "    print(\"  üë§ UserContext plugin\")\n",
    "    print(\"  üß† Enhanced DAX Generation plugin (real LLM)\")\n",
    "    print(\"  üîê Authentication plugin\")\n",
    "    print(\"  üìä Query Execution plugin\")\n",
    "    \n",
    "    return kernel\n",
    "\n",
    "# Production Agent - Complete End-to-End Workflow\n",
    "async def production_dax_copilot_agent(question: str, user_type: str = \"regular\"):\n",
    "    \"\"\"\n",
    "    üè≠ PRODUCTION AGENT: Complete agentic workflow\n",
    "    Context ‚Üí LLM ‚Üí Authentication ‚Üí Query Execution ‚Üí Results\n",
    "    \"\"\"\n",
    "    print(f\"üè≠ Production DAX Copilot Agent Processing: '{question}'\")\n",
    "    print(f\"üë§ User Type: {user_type}\")\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Determine user context and RLS requirements\n",
    "        print(\"\\nüìã Step 1: Determining user context...\")\n",
    "        user_context = await production_kernel.invoke(\n",
    "            function_name=\"get_user_rls_context\",\n",
    "            plugin_name=\"UserContext\", \n",
    "            user_type=user_type\n",
    "        )\n",
    "        print(\"‚úÖ User context determined\")\n",
    "        \n",
    "        # Step 2: Generate DAX query with real Azure OpenAI\n",
    "        print(\"\\nüß† Step 2: Generating DAX query with Azure OpenAI...\")\n",
    "        dax_query = await production_kernel.invoke(\n",
    "            function_name=\"generate_dax_query_llm\",\n",
    "            plugin_name=\"DAXGeneration\",\n",
    "            question=question,\n",
    "            user_context=user_context.value\n",
    "        )\n",
    "        print(\"‚úÖ DAX query generated with real LLM\")\n",
    "        print(f\"Generated DAX (preview): {dax_query.value[:80]}...\")\n",
    "        \n",
    "        # Step 3: Acquire Power BI access token\n",
    "        print(\"\\nüîê Step 3: Acquiring Power BI access token...\")\n",
    "        token_result = await production_kernel.invoke(\n",
    "            function_name=\"get_powerbi_token\",\n",
    "            plugin_name=\"Authentication\"\n",
    "        )\n",
    "        print(\"‚úÖ Access token acquired\")\n",
    "        \n",
    "        # Step 4: Execute DAX query against Power BI\n",
    "        print(\"\\nüìä Step 4: Executing DAX query against Power BI...\")\n",
    "        query_result = await production_kernel.invoke(\n",
    "            function_name=\"execute_dax_query\",\n",
    "            plugin_name=\"QueryExecution\",\n",
    "            dax_query=dax_query.value,\n",
    "            access_token=token_result.value\n",
    "        )\n",
    "        print(\"‚úÖ DAX query executed\")\n",
    "        \n",
    "        # Parse and return complete results\n",
    "        result_data = json.loads(query_result.value)\n",
    "        \n",
    "        return {\n",
    "            'question': question,\n",
    "            'user_context': json.loads(user_context.value),\n",
    "            'dax_query': dax_query.value,\n",
    "            'execution_result': result_data,\n",
    "            'workflow_complete': True,\n",
    "            'agent_type': 'production'\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'question': question,\n",
    "            'error': str(e),\n",
    "            'workflow_complete': False,\n",
    "            'agent_type': 'production'\n",
    "        }\n",
    "\n",
    "# Initialize the production kernel\n",
    "production_kernel = await initialize_production_kernel()\n",
    "print(\"\\nüöÄ Production system ready!\")\n",
    "print(\"Use: await production_dax_copilot_agent('your question', 'regular|rls')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ QueryExecutionPlugin created successfully!\n",
      "üìä Configured for: embed-customcopilot/adventuerworks2017\n"
     ]
    }
   ],
   "source": [
    "# üìä QueryExecutionPlugin - Execute DAX Against Power BI\n",
    "class QueryExecutionPlugin:\n",
    "    \"\"\"Plugin to execute DAX queries against Power BI semantic model\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.workspace = POWERBI_WORKSPACE\n",
    "        self.semantic_model = SEMANTIC_MODEL\n",
    "        \n",
    "    @kernel_function(\n",
    "        description=\"Executes a DAX query against Power BI semantic model and returns DataFrame\",\n",
    "        name=\"execute_dax_query\",\n",
    "    )\n",
    "    def execute_dax_query(\n",
    "        self,\n",
    "        dax_query: Annotated[str, \"The DAX query to execute\"],\n",
    "        access_token: Annotated[str, \"JSON string containing access token information\"]\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Executes DAX query against Power BI semantic model using ADOMD.NET\n",
    "        Returns: JSON string with query results or error information\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Parse access token\n",
    "            token_info = json.loads(access_token)\n",
    "            if token_info.get('status') != 'success':\n",
    "                return json.dumps({\n",
    "                    'status': 'error',\n",
    "                    'error': 'Invalid access token',\n",
    "                    'data': None\n",
    "                })\n",
    "            \n",
    "            # Setup ADOMD.NET\n",
    "            import clr\n",
    "            import sys\n",
    "            sys.path.append(r'C:\\Program Files\\Microsoft.NET\\ADOMD.NET\\160')\n",
    "            clr.AddReference('Microsoft.AnalysisServices.AdomdClient')\n",
    "            \n",
    "            from Microsoft.AnalysisServices.AdomdClient import AdomdConnection, AdomdCommand, AccessToken as AdomdAccessToken\n",
    "            from System import DateTimeOffset\n",
    "            \n",
    "            # Create CLR access token\n",
    "            access_token_str = token_info['access_token']\n",
    "            expiry = DateTimeOffset.FromUnixTimeSeconds(token_info['expires_at'])\n",
    "            token_obj = AdomdAccessToken(access_token_str, expiry, None)\n",
    "            \n",
    "            # Build connection string\n",
    "            connection_string = (\n",
    "                f\"Provider=MSOLAP;\"\n",
    "                f\"Data Source=powerbi://api.powerbi.com/v1.0/myorg/{self.workspace};\"\n",
    "                f\"Initial Catalog={self.semantic_model};\"\n",
    "            )\n",
    "            \n",
    "            # Execute query\n",
    "            conn = AdomdConnection(connection_string)\n",
    "            conn.AccessToken = token_obj\n",
    "            conn.Open()\n",
    "            \n",
    "            try:\n",
    "                cmd = AdomdCommand(dax_query, conn)\n",
    "                reader = cmd.ExecuteReader()\n",
    "                \n",
    "                # Get column names\n",
    "                columns = [reader.GetName(i) for i in range(reader.FieldCount)]\n",
    "                \n",
    "                # Read all rows\n",
    "                rows = []\n",
    "                while reader.Read():\n",
    "                    row = []\n",
    "                    for i in range(reader.FieldCount):\n",
    "                        val = reader.GetValue(i)\n",
    "                        if 'System.Decimal' in str(type(val)):\n",
    "                            val = float(val.ToString())\n",
    "                        row.append(val)\n",
    "                    rows.append(row)\n",
    "                \n",
    "                reader.Close()\n",
    "                \n",
    "            finally:\n",
    "                conn.Close()\n",
    "            \n",
    "            # Return results as JSON\n",
    "            result = {\n",
    "                'status': 'success',\n",
    "                'columns': columns,\n",
    "                'rows': rows,\n",
    "                'row_count': len(rows),\n",
    "                'executed_query': dax_query\n",
    "            }\n",
    "            \n",
    "            return json.dumps(result, indent=2)\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_result = {\n",
    "                'status': 'error',\n",
    "                'error_message': str(e),\n",
    "                'data': None,\n",
    "                'attempted_query': dax_query\n",
    "            }\n",
    "            return json.dumps(error_result, indent=2)\n",
    "\n",
    "# Test the QueryExecutionPlugin (will need valid token and DAX query)\n",
    "query_plugin = QueryExecutionPlugin()\n",
    "print(\"‚úÖ QueryExecutionPlugin created successfully!\")\n",
    "print(f\"üìä Configured for: {query_plugin.workspace}/{query_plugin.semantic_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üß™ TESTING COMPLETE AGENTIC WORKFLOW - REGULAR USER\n",
      "============================================================\n",
      "ü§ñ Complete DAX Copilot Agent Processing: 'Show Sales by Year'\n",
      "üë§ User Type: regular\n",
      "\n",
      "üìã Step 1: Determining user context...\n",
      "‚úÖ User context determined\n",
      "\n",
      "üß† Step 2: Generating DAX query with LLM...\n",
      "‚úÖ DAX query generated with LLM\n",
      "Generated DAX: EVALUATE\n",
      "SUMMARIZECOLUMNS(\n",
      "    DimDate[CalendarYear],\n",
      "    \"Sales\", [Sales]\n",
      ")...\n",
      "\n",
      "üîê Step 3: Acquiring Power BI access token...\n",
      "‚úÖ Access token acquired\n",
      "\n",
      "üìä Step 4: Executing DAX query against Power BI...\n",
      "‚úÖ DAX query executed\n",
      "\n",
      "üìä REGULAR USER RESULTS:\n",
      "Question: Show Sales by Year\n",
      "User Type: regular\n",
      "RLS Applied: No\n",
      "\n",
      "üìú COMPLETE Generated DAX Query:\n",
      "==================================================\n",
      "EVALUATE\n",
      "SUMMARIZECOLUMNS(\n",
      "    DimDate[CalendarYear],\n",
      "    \"Sales\", [Sales]\n",
      ")\n",
      "==================================================\n",
      "\n",
      "üìà Query Results:\n",
      "Columns: ['DimDate[CalendarYear]', '[Sales]']\n",
      "Row Count: 4\n",
      "‚úÖ Regular user workflow completed successfully!\n",
      "\n",
      "üìä COMPLETE Data Results (all 4 rows):\n",
      "Row 1: [2011, 6852489.3846]\n",
      "Row 2: [2012, 5836345.8175]\n",
      "Row 3: [2013, 16044747.2986]\n",
      "Row 4: [2014, 625094.72]\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# üß™ Test Complete Agentic Workflow - Regular User\n",
    "print(\"=\" * 60)\n",
    "print(\"üß™ TESTING COMPLETE AGENTIC WORKFLOW - REGULAR USER\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "regular_result = await complete_dax_copilot_agent(\"Show Sales by Year\", \"regular\")\n",
    "\n",
    "if regular_result['workflow_complete']:\n",
    "    print(f\"\\nüìä REGULAR USER RESULTS:\")\n",
    "    print(f\"Question: {regular_result['question']}\")\n",
    "    print(f\"User Type: {regular_result['user_context']['user_type']}\")\n",
    "    print(f\"RLS Applied: {'Yes' if regular_result['user_context']['rls_filter'] else 'No'}\")\n",
    "    print(f\"\\nüìú COMPLETE Generated DAX Query:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(regular_result['dax_query'])\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    exec_result = regular_result['execution_result']\n",
    "    if exec_result['status'] == 'success':\n",
    "        print(f\"\\nüìà Query Results:\")\n",
    "        print(f\"Columns: {exec_result['columns']}\")\n",
    "        print(f\"Row Count: {exec_result['row_count']}\")\n",
    "        print(\"‚úÖ Regular user workflow completed successfully!\")\n",
    "        \n",
    "        # Display ALL rows for complete comparison\n",
    "        if exec_result['rows']:\n",
    "            print(f\"\\nüìä COMPLETE Data Results (all {exec_result['row_count']} rows):\")\n",
    "            for i, row in enumerate(exec_result['rows']):\n",
    "                print(f\"Row {i+1}: {row}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Query execution failed: {exec_result['error_message']}\")\n",
    "else:\n",
    "    print(f\"‚ùå Workflow failed: {regular_result.get('error', 'Unknown error')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üß™ TESTING COMPLETE AGENTIC WORKFLOW - RLS USER\n",
      "============================================================\n",
      "ü§ñ Complete DAX Copilot Agent Processing: 'Show Sales by Year'\n",
      "üë§ User Type: rls\n",
      "\n",
      "üìã Step 1: Determining user context...\n",
      "‚úÖ User context determined\n",
      "\n",
      "üß† Step 2: Generating DAX query with LLM...\n",
      "‚úÖ DAX query generated with LLM\n",
      "Generated DAX: EVALUATE\n",
      "SUMMARIZE(\n",
      "    FILTER(\n",
      "        FactInternetSales,\n",
      "        RELATED(DimSalesTerritory[Sales T...\n",
      "\n",
      "üîê Step 3: Acquiring Power BI access token...\n",
      "‚úÖ Access token acquired\n",
      "\n",
      "üìä Step 4: Executing DAX query against Power BI...\n",
      "‚úÖ DAX query executed\n",
      "\n",
      "üìä RLS USER RESULTS:\n",
      "Question: Show Sales by Year\n",
      "User Type: rls\n",
      "RLS Applied: Yes\n",
      "RLS Filter Applied: DimSalesTerritory[Sales Territory Country] = \"Canada\"\n",
      "\n",
      "üìú COMPLETE Generated DAX Query (with RLS filter):\n",
      "==================================================\n",
      "EVALUATE\n",
      "SUMMARIZE(\n",
      "    FILTER(\n",
      "        FactInternetSales,\n",
      "        RELATED(DimSalesTerritory[Sales Territory Country]) = \"Canada\"\n",
      "    ),\n",
      "    DimDate[CalendarYear],\n",
      "    \"Sales\", [Sales]\n",
      ")\n",
      "==================================================\n",
      "\n",
      "üìà Query Results:\n",
      "Columns: ['DimDate[CalendarYear]', '[Sales]']\n",
      "Row Count: 4\n",
      "‚úÖ RLS user workflow completed successfully!\n",
      "\n",
      "üìä COMPLETE Data Results (all 4 rows):\n",
      "Row 1: [2011, 555412.9002]\n",
      "Row 2: [2012, 320649.6637]\n",
      "Row 3: [2013, 1054987.9782]\n",
      "Row 4: [2014, 46794.32]\n",
      "\n",
      "============================================================\n",
      "üìä DETAILED WORKFLOW COMPARISON SUMMARY\n",
      "============================================================\n",
      "üî¢ DATA COMPARISON:\n",
      "  Regular User Results: 4 rows\n",
      "  RLS User Results: 4 rows\n",
      "  Difference: 0 rows filtered by RLS\n",
      "\n",
      "üîç DAX QUERY COMPARISON:\n",
      "  Regular Query Length: 76 characters\n",
      "  RLS Query Length: 186 characters\n",
      "  RLS Filter Detected: True\n",
      "\n",
      "üìä DATA VALUES COMPARISON:\n",
      "  Regular User - Sample Values:\n",
      "    Year 2011: $6,852,489.38\n",
      "    Year 2012: $5,836,345.82\n",
      "  RLS User - Sample Values:\n",
      "    Year 2011: $555,412.90\n",
      "    Year 2012: $320,649.66\n",
      "\n",
      "üéØ Agentic Architecture Benefits:\n",
      "‚úÖ Plugin-based modularity\n",
      "‚úÖ Consistent workflow orchestration\n",
      "‚úÖ Automatic RLS context handling\n",
      "‚úÖ Real LLM integration\n",
      "‚úÖ Error handling and logging\n",
      "‚úÖ Testable and maintainable code\n",
      "\n",
      "üèóÔ∏è Architecture Complete!\n",
      "4/4 plugins implemented and working:\n",
      "  üë§ UserContextPlugin\n",
      "  üß† DAXGenerationPlugin\n",
      "  üîê AuthenticationPlugin\n",
      "  üìä QueryExecutionPlugin\n"
     ]
    }
   ],
   "source": [
    "# üß™ Test Complete Agentic Workflow - RLS User\n",
    "print(\"=\" * 60)\n",
    "print(\"üß™ TESTING COMPLETE AGENTIC WORKFLOW - RLS USER\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "rls_result = await complete_dax_copilot_agent(\"Show Sales by Year\", \"rls\")\n",
    "\n",
    "if rls_result['workflow_complete']:\n",
    "    print(f\"\\nüìä RLS USER RESULTS:\")\n",
    "    print(f\"Question: {rls_result['question']}\")\n",
    "    print(f\"User Type: {rls_result['user_context']['user_type']}\")\n",
    "    print(f\"RLS Applied: {'Yes' if rls_result['user_context']['rls_filter'] else 'No'}\")\n",
    "    if rls_result['user_context']['rls_filter']:\n",
    "        print(f\"RLS Filter Applied: {rls_result['user_context']['rls_filter']}\")\n",
    "    \n",
    "    print(f\"\\nüìú COMPLETE Generated DAX Query (with RLS filter):\")\n",
    "    print(\"=\" * 50)\n",
    "    print(rls_result['dax_query'])\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    exec_result = rls_result['execution_result']\n",
    "    if exec_result['status'] == 'success':\n",
    "        print(f\"\\nüìà Query Results:\")\n",
    "        print(f\"Columns: {exec_result['columns']}\")\n",
    "        print(f\"Row Count: {exec_result['row_count']}\")\n",
    "        print(\"‚úÖ RLS user workflow completed successfully!\")\n",
    "        \n",
    "        # Display ALL rows for complete comparison\n",
    "        if exec_result['rows']:\n",
    "            print(f\"\\nüìä COMPLETE Data Results (all {exec_result['row_count']} rows):\")\n",
    "            for i, row in enumerate(exec_result['rows']):\n",
    "                print(f\"Row {i+1}: {row}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Query execution failed: {exec_result['error_message']}\")\n",
    "else:\n",
    "    print(f\"‚ùå Workflow failed: {rls_result.get('error', 'Unknown error')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# üìä Results Comparison\n",
    "print(\"üìä DETAILED WORKFLOW COMPARISON SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if 'regular_result' in locals() and 'rls_result' in locals():\n",
    "    if regular_result['workflow_complete'] and rls_result['workflow_complete']:\n",
    "        reg_rows = regular_result['execution_result'].get('row_count', 0)\n",
    "        rls_rows = rls_result['execution_result'].get('row_count', 0)\n",
    "        \n",
    "        print(f\"üî¢ DATA COMPARISON:\")\n",
    "        print(f\"  Regular User Results: {reg_rows} rows\")\n",
    "        print(f\"  RLS User Results: {rls_rows} rows\")\n",
    "        print(f\"  Difference: {reg_rows - rls_rows} rows filtered by RLS\")\n",
    "        \n",
    "        print(f\"\\nüîç DAX QUERY COMPARISON:\")\n",
    "        print(f\"  Regular Query Length: {len(regular_result['dax_query'])} characters\")\n",
    "        print(f\"  RLS Query Length: {len(rls_result['dax_query'])} characters\")\n",
    "        print(f\"  RLS Filter Detected: {'FILTER(' in rls_result['dax_query'] or 'Canada' in rls_result['dax_query']}\")\n",
    "        \n",
    "        if regular_result['execution_result']['status'] == 'success' and rls_result['execution_result']['status'] == 'success':\n",
    "            reg_data = regular_result['execution_result']['rows']\n",
    "            rls_data = rls_result['execution_result']['rows']\n",
    "            \n",
    "            print(f\"\\nüìä DATA VALUES COMPARISON:\")\n",
    "            if reg_data and rls_data:\n",
    "                print(\"  Regular User - Sample Values:\")\n",
    "                for i, row in enumerate(reg_data[:2]):\n",
    "                    print(f\"    Year {row[0]}: ${row[1]:,.2f}\")\n",
    "                \n",
    "                print(\"  RLS User - Sample Values:\")\n",
    "                for i, row in enumerate(rls_data[:2]):\n",
    "                    print(f\"    Year {row[0]}: ${row[1]:,.2f}\")\n",
    "        \n",
    "        print(f\"\\nüéØ Agentic Architecture Benefits:\")\n",
    "        print(f\"‚úÖ Plugin-based modularity\")\n",
    "        print(f\"‚úÖ Consistent workflow orchestration\")\n",
    "        print(f\"‚úÖ Automatic RLS context handling\")\n",
    "        print(f\"‚úÖ Real LLM integration\")\n",
    "        print(f\"‚úÖ Error handling and logging\")\n",
    "        print(f\"‚úÖ Testable and maintainable code\")\n",
    "        \n",
    "        print(f\"\\nüèóÔ∏è Architecture Complete!\")\n",
    "        print(f\"4/4 plugins implemented and working:\")\n",
    "        print(f\"  üë§ UserContextPlugin\")  \n",
    "        print(f\"  üß† DAXGenerationPlugin\")\n",
    "        print(f\"  üîê AuthenticationPlugin\")\n",
    "        print(f\"  üìä QueryExecutionPlugin\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è One or both workflows failed - check error messages above\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Results not available for comparison\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
